{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Employee Performance Analysis - INX Future Inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      \n",
    "    Candidate Name      : Sankar S\n",
    "    E-Mail              : sansandeep2727@gmail.com\n",
    "    Project Code        : 10281 \n",
    "    REP Name            : DataMites™ Solutions Pvt Ltd\n",
    "    Assesment ID        : E10901-PR2-V18\n",
    "    Module              : Certified Data Scientist - Project\n",
    "    Exam Format         : Open Project- IABAC™ Project Submission\n",
    "    Registered Trainer  : Ashok Kumar A\n",
    "    Submission Deadline Date:\t20-April-2019  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "\n",
    "The Data science project which is given here is an analysis of employee performance form INX Furture Inc. The project goal is to find the performance rating of the employees from each feature of their data such as total work experience, gender, department, current role..etc. The Goal and Insights of the project as follows,\n",
    "\n",
    "1. Department wise performances\n",
    "2. Top 3 Important Factors affecting employee performance\n",
    "3. A trained model which can predict the employee performance based on factors as inputs. This will be used to hire employees\n",
    "4. Recommendations to improve the employee performance based on insights from analysis.\n",
    "\n",
    "The given data of employees has the 1200 data to perform a higher level machine learning where it is well structured. The features present in the data are 28 in total. The Shape of the data is 1200x28. The 28 features are classified into quantitative and qualitative where 16 features are qualitative and 11 features are quantitative. The employee ID data is alphanumerical data which doesn't play a role as a relevant feature for performance rating.\n",
    "\n",
    "The dataset is a complete labelled data and categorical which decides the machine learning algorithm to be used. The important aspects of the data are depending on the correlation of data between features and performance rating. The analysis of the project has gone through the stage of distribution analysis, correlation analysis and analysis by each department to satisfy the project goal.\n",
    "\n",
    "The machine learning model which is used in this project is random forest classifier and gradient boosted classifier which predicted the nearby higher accuracy of 92%. Since it is categorical labelled data, it has to go through the classifier machine learning techniques which will be suitable for this structured data. The numerical features are the most relevant in the model according to correlation technique. \n",
    "\n",
    "One of the goals of this project is to find the important feature affecting the performance rating. The important features were predicted using the machine learning model feature importance technique.  The main technique used in the preprocessing data using the one hot encoding method to convert the string-categorical data into numerical data, because, the most of machine learning methods are based on numerical methods where strings are not supportive. The overall project was performed and achieved the goals by using the machine learning model and visualization techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<brc>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirement\n",
    "The data was given from the IABAC for this project where the collected source is IABAC. The data is based on INX Future Inc, (referred as INX ). It is one of the leading data analytics and automation solutions provider with over 15 years of global business presence. The data is not from the real organization.  The whole project was done in Jupiter notebook with python platform.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<brc>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were analyzed by describing the features present in the data. the features play the bigger part in the analysis. the features tell the relation between the dependent and independent variables. Pandas also help to describe the datasets answering following questions early in our project. The futures present in the data are divided into numerical and categorical data. \n",
    "\n",
    "###  Categorical  Features\n",
    "These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based. The categorical features as follows, \n",
    "\n",
    "- Gender\n",
    "- EducationBackground\n",
    "- MaritalStatus\n",
    "- EmpDepartment\n",
    "- EmpJobRole\n",
    "- BusinessTravelFrequency\n",
    "- EmpEducationLevel\n",
    "- EmpEnvironmentSatisfaction\n",
    "- EmpJobInvolvement\n",
    "- EmpJobLevel\n",
    "- EmpJobSatisfaction\n",
    "- OverTime\n",
    "- EmpRelationshipSatisfaction\n",
    "- EmpWorkLifeBalance\n",
    "- Attrition\n",
    "- PerformanceRating\n",
    "\n",
    "\n",
    "###  Numerical Features \n",
    "These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based. The Numerical Features as follows, \n",
    "\n",
    "- Age\n",
    "- DistanceFromHome\n",
    "- EmpHourlyRate\n",
    "- NumCompaniesWorked\n",
    "- EmpLastSalaryHikePercent\n",
    "- TotalWorkExperienceInYears\n",
    "- TrainingTimesLastYear\n",
    "- ExperienceYearsAtThisCompany\n",
    "- ExperienceYearsInCurrentRole\n",
    "- YearsSinceLastPromotion\n",
    "- YearsWithCurrManager\n",
    "\n",
    "### Alphanumeric Features \n",
    "Numerical, alphanumeric data within same feature. These are candidates for correcting goal.\n",
    "Employee ID number is a mix of numeric and alphanumeric data types.\n",
    "\n",
    "### Distribution of Numerical Features\n",
    "This helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.the distribution can be derived or visualized using the density map between the numerical or categorical features present in the data. \n",
    "\n",
    "- The age distribution is starting from 18 to 60 where the most of the employees are lying between **30 to 40** age count.\n",
    "- The distance from home to office is distributing from 0 unit to 30 unit which can be kilometre or mile. The most of the employees are coming from the range of 0 to 5 units.\n",
    "- Employees are worked in the multiple companies up to **8** companies where most of the employees worked up to **2** companies before getting to work here.\n",
    "- The hourly rate range is **65 to 95** for majority employees work in this company.\n",
    "- In General, Most of Employees work up to **5** years in this company.\n",
    "- Most of the employees get 11%  to 15% of salary hike in this company.\n",
    "\n",
    "### Distribution of Categorical Features\n",
    "\n",
    "- The Gender variance is divided by **60%** of Male employees and **40%** of Female employees in the company. \n",
    "- The number of the educational backgrounds present in the employees is **six** unique backgrounds.\n",
    "- nineteen unique employee job roles are present in this company.\n",
    "- The most of the employees are having the education level of **3**\n",
    "- The Job satisfaction level in this company is high level for the majority of employees.\n",
    "- The **85%** of employees are not having attrition in their work\n",
    "- only **11%** of employees in the company were achieved **level 4** - performance rating \n",
    "- The overall percentage of employees doing overtime is **30%**\n",
    "\n",
    "### Data Clean Check \n",
    "\n",
    "The Data cleaning and wrangling is the part of the Data science project where the workflow the project go through this stage. because the damaged and missing data will lead to the disaster in the accuracy and quality of the model. If the data is already structured and cleaned, there is no need for the data cleaning. In this case, the given data is well structured and cleaned and there are no missing data present in this data. \n",
    "\n",
    "### Analysis by Visualization\n",
    "we can able to perform the analysis by the visualisation of the data in two forms here in this project. One is by distributing the data and visualize using the density plotting. The other one is nothing but the correlation method which will visualise the correlation heat map and we can able to achieve the correlation values between the numerical features. \n",
    "\n",
    "### (i) Distribution Plot\n",
    "In general, one of the first few steps in exploring the data would be to have a rough idea of how the features are distributed with one another. To do so, we shall invoke the familiar kdeplot function from the Seaborn plotting library. The distribution has been done by both numerical and categorical features. it will show the overall idea about the density and majority of data present in a different level.  \n",
    "\n",
    "### (ii) Correlation Plot\n",
    "The next tool in a data explorer's arsenal is that of a correlation matrix. By plotting a correlation matrix, we have a very nice overview of how the features are related to one another. For a Pandas data frame, we can conveniently use the call .corr which by default provides the Pearson Correlation values of the columns pairwise in that data frame. The correlation works bet for numerical data where we are going to use all the numerical features present in the data. \n",
    "\n",
    "From the above Pearson correlation heat plot, we can be to see that correlation between features with numerical values in the dataset. The heat signatures show the level of correlation from 0 to 1. from this distribution we can derive the facts as follows, \n",
    "\n",
    "- The Total years of experience and job level are having the higher correlation when comparing to all features.\n",
    "\n",
    "- Experience years at this company and years with the current manager has the second higher relation between these features.\n",
    "\n",
    "- Experience years at this company and experience in the current role makes the sense of correlation.\n",
    "\n",
    "- People who have more experience with the company has the more probability to get the promotion from the correlation between them.\n",
    "\n",
    "- In this plot, the age has the important role in the total number of work experience of an employee where it is a universal truth.\n",
    "\n",
    "\n",
    "### Machine Learning Model \n",
    "The machine learning models used in this project are\n",
    "\n",
    "\n",
    "- 1.Random Forest classifier \n",
    "- 2.Gradient boosted Classifier\n",
    "\n",
    "\n",
    "Both machine learning algorithms are best for classification and labelled data. The train and test data are divided and fitted into the model and passed through the machine learning. Since we have already noted the severe imbalance in the values within the target variable, we implement the SMOTE method in the dealing with this skewed value via the learn Python package. The predicted data and test data achieved the accuracy rate of, \n",
    "\n",
    "-  Random Forest classifier: 92%\n",
    "- Gradient boosted Classifier: 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "The machine learning model has been fitted and predicted with the accuracy score. The goal of this project is nothing but the results from the analysis and machine learning model. \n",
    "\n",
    "### Goal 1: Department wise performances\n",
    "\n",
    "In department wise performance, we have to analyze the data from each department present in the category. The data frame has to be separated or sliced according to department wise. In Employee department feature there are six departments available. The performance  analysis by the department as follows,\n",
    "\n",
    "- **Sales**:  The Performace rating level 3 is more in the sales department. The male performance rating the little bit higher compared to female. The total work experience does not count the performance rating. \n",
    " \n",
    "- **Human Resources**:  The majority of the employees lying under the level 3 performance.  The older people are performing low in this department. The female employees in HR department doing really well in their performance. The total work experience does matter to performance in this department. \n",
    "\n",
    "- **Development**:  The largest number of employees are level 3 performers.  Employees of all age are performing at the level of 3 only.  The gender-based performance is nearly same for both. \n",
    "\n",
    "- **Data Science**:  The highest average of level 3 performance is in data science department. Data science is the only department where less number of level 2 performers. The overall performance is higher compared to all departments. The age does not count as an important factor in their performance. Male employees are doing good in this department. Same like HR, the number of work experience does matter.\n",
    "\n",
    "- **Research & Development**: The age factor is not deviating from the level of performance here where different employees with different age are there in every level of performance.  The R&D has the good female employees in their performance. \n",
    "\n",
    "- **Finance**:  The finance department performance is exponentially decreasing when age increases. The male employees are doing good. The experience factor is inversely relating to the performance level. \n",
    "\n",
    "### Goal 2: The Top  3 important features affecting the employee performance \n",
    "\n",
    "The Random Forest classifier and Gradient boosted classifier in Sklearn also contains a very convenient and most useful attribute feature importances which tells us which features within our dataset has been given most importance through the ML.  The top three important features affecting the performance rating are ordered with their importance level as follows, \n",
    "\n",
    "    1. Employment Environment Satisfaction\n",
    "    2. Employee Salary Hike Percentage\n",
    "    3. Years Since the last Promotion\n",
    "    \n",
    "### Goal 3: A Trained model which can predict the employee performance\n",
    "\n",
    "The trained model is created using the machine learning algorithm as follows with the accuracy score, \n",
    "- Random Forest classifier: 92% accuracy\n",
    "- Gradient boosted Classifier: 91% accuracy\n",
    "\n",
    "### Goal 4: Recommendations to improve the employee performance\n",
    "- The overall employee performance can be achieved by employee environment satisfaction. The company needs to focus more on the employee environment. \n",
    "- The salary hike will give the boost to the employees to perform well financially and psychologically.\n",
    "- The promotion will help the employees to achieve more performance by giving the chance to be more responsible and leadership qualities. \n",
    "- The experience years in current role need to be revised while offering the employment to the new employees. \n",
    "- Employee's work-life balance affects the performance rating. \n",
    "- While recruiting for HR, consider the female candidates where they perform well compared to male.\n",
    "- The development and data science department is having an overall higher performance comparing to rest of the departments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
